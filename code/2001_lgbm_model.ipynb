{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SMOTE is not implemented properly, train on oversampled data, validate on original data ratio\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import ensemble\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.32it/s]\r",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s]\r",
      "100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train = utils.read_pickles('../data/input/smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1        2       3        4       5       6        7       8    \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "      9     ...       190     191     192      193      194     195     196  \\\n",
       "0  5.7470   ...    4.4354  3.9642  3.1364   1.6910  18.5227 -2.3978  7.8784   \n",
       "1  8.0851   ...    7.6421  7.7214  2.5837  10.9516  15.4305  2.0339  8.1267   \n",
       "2  5.9525   ...    2.9057  9.7905  1.6704   1.6858  21.6042  3.1417 -6.5213   \n",
       "3  8.2450   ...    4.4666  4.7433  0.7178   1.4214  23.0347 -1.2706 -2.9275   \n",
       "4  7.6784   ...   -1.4905  9.5214 -0.1508   9.1942  13.2876 -1.5121  3.9267   \n",
       "\n",
       "       197      198     199  \n",
       "0   8.5635  12.7803 -1.0914  \n",
       "1   8.7889  18.3560  1.9518  \n",
       "2   8.2675  14.7222  0.3965  \n",
       "3  10.2922  17.9697 -8.9996  \n",
       "4   9.5031  17.9974 -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '../data/input/test.csv'\n",
    "\n",
    "df_test = pd.read_csv(test_file)\n",
    "test_id = df_test.pop('ID_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {'num_leaves': 9,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.0123,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.728910519108444,\n",
    "         'reg_lambda': 4.9847051755586085,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01077313523861969,\n",
    "         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Thu Feb 28 19:37:49 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.902204\tvalid_1's auc: 0.895634\n",
      "[600]\ttraining's auc: 0.926824\tvalid_1's auc: 0.919637\n",
      "[900]\ttraining's auc: 0.937308\tvalid_1's auc: 0.929657\n",
      "[1200]\ttraining's auc: 0.944171\tvalid_1's auc: 0.936147\n",
      "[1500]\ttraining's auc: 0.948883\tvalid_1's auc: 0.940565\n",
      "[1800]\ttraining's auc: 0.952679\tvalid_1's auc: 0.944181\n",
      "[2100]\ttraining's auc: 0.955695\tvalid_1's auc: 0.947088\n",
      "[2400]\ttraining's auc: 0.958185\tvalid_1's auc: 0.949441\n",
      "[2700]\ttraining's auc: 0.960327\tvalid_1's auc: 0.951438\n",
      "[3000]\ttraining's auc: 0.962104\tvalid_1's auc: 0.953104\n",
      "[3300]\ttraining's auc: 0.963631\tvalid_1's auc: 0.954467\n",
      "[3600]\ttraining's auc: 0.964989\tvalid_1's auc: 0.955712\n",
      "[3900]\ttraining's auc: 0.966183\tvalid_1's auc: 0.95674\n",
      "[4200]\ttraining's auc: 0.967251\tvalid_1's auc: 0.957687\n",
      "[4500]\ttraining's auc: 0.96817\tvalid_1's auc: 0.958444\n",
      "[4800]\ttraining's auc: 0.969019\tvalid_1's auc: 0.95919\n",
      "[5100]\ttraining's auc: 0.969793\tvalid_1's auc: 0.959855\n",
      "[5400]\ttraining's auc: 0.970494\tvalid_1's auc: 0.960453\n",
      "[5700]\ttraining's auc: 0.97116\tvalid_1's auc: 0.961033\n",
      "[6000]\ttraining's auc: 0.971757\tvalid_1's auc: 0.961527\n",
      "[6300]\ttraining's auc: 0.97233\tvalid_1's auc: 0.961987\n",
      "[6600]\ttraining's auc: 0.972873\tvalid_1's auc: 0.962424\n",
      "[6900]\ttraining's auc: 0.973404\tvalid_1's auc: 0.962813\n",
      "[7200]\ttraining's auc: 0.973907\tvalid_1's auc: 0.963213\n",
      "[7500]\ttraining's auc: 0.974418\tvalid_1's auc: 0.963594\n",
      "[7800]\ttraining's auc: 0.974917\tvalid_1's auc: 0.963932\n",
      "[8100]\ttraining's auc: 0.97542\tvalid_1's auc: 0.964276\n",
      "[8400]\ttraining's auc: 0.975913\tvalid_1's auc: 0.964591\n",
      "[8700]\ttraining's auc: 0.976393\tvalid_1's auc: 0.964901\n",
      "[9000]\ttraining's auc: 0.976891\tvalid_1's auc: 0.965225\n",
      "[9300]\ttraining's auc: 0.977375\tvalid_1's auc: 0.965513\n",
      "[9600]\ttraining's auc: 0.977845\tvalid_1's auc: 0.965818\n",
      "[9900]\ttraining's auc: 0.978282\tvalid_1's auc: 0.966091\n",
      "[10200]\ttraining's auc: 0.978721\tvalid_1's auc: 0.966349\n",
      "[10500]\ttraining's auc: 0.979171\tvalid_1's auc: 0.966614\n",
      "[10800]\ttraining's auc: 0.979597\tvalid_1's auc: 0.966862\n",
      "[11100]\ttraining's auc: 0.980026\tvalid_1's auc: 0.967112\n",
      "[11400]\ttraining's auc: 0.980449\tvalid_1's auc: 0.967368\n",
      "[11700]\ttraining's auc: 0.98086\tvalid_1's auc: 0.967623\n",
      "[12000]\ttraining's auc: 0.981257\tvalid_1's auc: 0.967855\n",
      "[12300]\ttraining's auc: 0.981649\tvalid_1's auc: 0.968088\n",
      "[12600]\ttraining's auc: 0.982035\tvalid_1's auc: 0.968317\n",
      "[12900]\ttraining's auc: 0.982409\tvalid_1's auc: 0.968533\n",
      "[13200]\ttraining's auc: 0.982784\tvalid_1's auc: 0.968758\n",
      "[13500]\ttraining's auc: 0.98315\tvalid_1's auc: 0.968981\n",
      "[13800]\ttraining's auc: 0.983492\tvalid_1's auc: 0.969193\n",
      "[14100]\ttraining's auc: 0.983838\tvalid_1's auc: 0.969399\n",
      "[14400]\ttraining's auc: 0.984188\tvalid_1's auc: 0.96961\n",
      "[14700]\ttraining's auc: 0.984525\tvalid_1's auc: 0.969818\n",
      "[15000]\ttraining's auc: 0.984846\tvalid_1's auc: 0.970022\n",
      "[15300]\ttraining's auc: 0.985174\tvalid_1's auc: 0.970229\n",
      "[15600]\ttraining's auc: 0.985489\tvalid_1's auc: 0.970432\n",
      "[15900]\ttraining's auc: 0.985798\tvalid_1's auc: 0.970623\n",
      "[16200]\ttraining's auc: 0.9861\tvalid_1's auc: 0.970809\n",
      "[16500]\ttraining's auc: 0.986404\tvalid_1's auc: 0.971005\n",
      "[16800]\ttraining's auc: 0.986697\tvalid_1's auc: 0.97119\n",
      "[17100]\ttraining's auc: 0.986994\tvalid_1's auc: 0.971374\n",
      "[17400]\ttraining's auc: 0.98727\tvalid_1's auc: 0.97155\n",
      "[17700]\ttraining's auc: 0.987554\tvalid_1's auc: 0.971736\n",
      "[18000]\ttraining's auc: 0.987844\tvalid_1's auc: 0.971937\n",
      "[18300]\ttraining's auc: 0.988109\tvalid_1's auc: 0.972112\n",
      "[18600]\ttraining's auc: 0.98837\tvalid_1's auc: 0.972284\n",
      "[18900]\ttraining's auc: 0.988628\tvalid_1's auc: 0.972454\n",
      "[19200]\ttraining's auc: 0.988882\tvalid_1's auc: 0.972627\n",
      "[19500]\ttraining's auc: 0.989135\tvalid_1's auc: 0.972796\n",
      "[19800]\ttraining's auc: 0.989382\tvalid_1's auc: 0.972959\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's auc: 0.989546\tvalid_1's auc: 0.973078\n",
      "Fold 1 started at Thu Feb 28 21:01:23 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.902654\tvalid_1's auc: 0.89512\n",
      "[600]\ttraining's auc: 0.92721\tvalid_1's auc: 0.919189\n",
      "[900]\ttraining's auc: 0.937418\tvalid_1's auc: 0.929001\n",
      "[1200]\ttraining's auc: 0.943973\tvalid_1's auc: 0.935479\n",
      "[1500]\ttraining's auc: 0.948773\tvalid_1's auc: 0.940122\n",
      "[1800]\ttraining's auc: 0.95255\tvalid_1's auc: 0.943784\n",
      "[2100]\ttraining's auc: 0.955593\tvalid_1's auc: 0.94677\n",
      "[2400]\ttraining's auc: 0.958035\tvalid_1's auc: 0.949081\n",
      "[2700]\ttraining's auc: 0.960181\tvalid_1's auc: 0.951193\n",
      "[3000]\ttraining's auc: 0.961977\tvalid_1's auc: 0.952895\n",
      "[3300]\ttraining's auc: 0.963433\tvalid_1's auc: 0.954278\n",
      "[3600]\ttraining's auc: 0.964714\tvalid_1's auc: 0.955525\n",
      "[3900]\ttraining's auc: 0.965878\tvalid_1's auc: 0.956617\n",
      "[4200]\ttraining's auc: 0.966945\tvalid_1's auc: 0.957612\n",
      "[4500]\ttraining's auc: 0.967883\tvalid_1's auc: 0.958518\n",
      "[4800]\ttraining's auc: 0.968741\tvalid_1's auc: 0.959275\n",
      "[5100]\ttraining's auc: 0.969524\tvalid_1's auc: 0.959989\n",
      "[5400]\ttraining's auc: 0.970247\tvalid_1's auc: 0.960638\n",
      "[5700]\ttraining's auc: 0.970911\tvalid_1's auc: 0.961201\n",
      "[6000]\ttraining's auc: 0.971508\tvalid_1's auc: 0.961732\n",
      "[6300]\ttraining's auc: 0.972097\tvalid_1's auc: 0.962235\n",
      "[6600]\ttraining's auc: 0.972636\tvalid_1's auc: 0.962672\n",
      "[6900]\ttraining's auc: 0.973181\tvalid_1's auc: 0.963089\n",
      "[7200]\ttraining's auc: 0.973711\tvalid_1's auc: 0.963486\n",
      "[7500]\ttraining's auc: 0.974231\tvalid_1's auc: 0.963867\n",
      "[7800]\ttraining's auc: 0.974741\tvalid_1's auc: 0.964235\n",
      "[8100]\ttraining's auc: 0.975253\tvalid_1's auc: 0.964592\n",
      "[8400]\ttraining's auc: 0.975751\tvalid_1's auc: 0.964931\n",
      "[8700]\ttraining's auc: 0.976242\tvalid_1's auc: 0.965254\n",
      "[9000]\ttraining's auc: 0.976731\tvalid_1's auc: 0.965571\n",
      "[9300]\ttraining's auc: 0.977226\tvalid_1's auc: 0.965882\n",
      "[9600]\ttraining's auc: 0.977699\tvalid_1's auc: 0.966177\n",
      "[9900]\ttraining's auc: 0.978153\tvalid_1's auc: 0.966466\n",
      "[10200]\ttraining's auc: 0.978599\tvalid_1's auc: 0.966745\n",
      "[10500]\ttraining's auc: 0.979041\tvalid_1's auc: 0.966998\n",
      "[10800]\ttraining's auc: 0.979482\tvalid_1's auc: 0.967277\n",
      "[11100]\ttraining's auc: 0.979909\tvalid_1's auc: 0.967527\n",
      "[11400]\ttraining's auc: 0.98033\tvalid_1's auc: 0.967789\n",
      "[11700]\ttraining's auc: 0.980738\tvalid_1's auc: 0.968025\n",
      "[12000]\ttraining's auc: 0.981142\tvalid_1's auc: 0.968279\n",
      "[12300]\ttraining's auc: 0.981546\tvalid_1's auc: 0.968535\n",
      "[12600]\ttraining's auc: 0.981933\tvalid_1's auc: 0.968779\n",
      "[12900]\ttraining's auc: 0.982313\tvalid_1's auc: 0.969004\n",
      "[13200]\ttraining's auc: 0.982682\tvalid_1's auc: 0.969233\n",
      "[13500]\ttraining's auc: 0.983047\tvalid_1's auc: 0.969451\n",
      "[13800]\ttraining's auc: 0.983397\tvalid_1's auc: 0.96966\n",
      "[14100]\ttraining's auc: 0.983758\tvalid_1's auc: 0.969885\n",
      "[14400]\ttraining's auc: 0.984114\tvalid_1's auc: 0.970113\n",
      "[14700]\ttraining's auc: 0.984465\tvalid_1's auc: 0.97033\n",
      "[15000]\ttraining's auc: 0.984795\tvalid_1's auc: 0.970538\n",
      "[15300]\ttraining's auc: 0.985123\tvalid_1's auc: 0.970757\n",
      "[15600]\ttraining's auc: 0.985436\tvalid_1's auc: 0.970954\n",
      "[15900]\ttraining's auc: 0.985749\tvalid_1's auc: 0.971156\n",
      "[16200]\ttraining's auc: 0.986056\tvalid_1's auc: 0.971347\n",
      "[16500]\ttraining's auc: 0.986359\tvalid_1's auc: 0.971535\n",
      "[16800]\ttraining's auc: 0.98665\tvalid_1's auc: 0.971736\n",
      "[17100]\ttraining's auc: 0.986942\tvalid_1's auc: 0.97193\n",
      "[17400]\ttraining's auc: 0.987226\tvalid_1's auc: 0.972106\n",
      "[17700]\ttraining's auc: 0.987512\tvalid_1's auc: 0.972296\n",
      "[18000]\ttraining's auc: 0.987782\tvalid_1's auc: 0.972468\n",
      "[18300]\ttraining's auc: 0.988044\tvalid_1's auc: 0.972639\n",
      "[18600]\ttraining's auc: 0.988311\tvalid_1's auc: 0.972826\n",
      "[18900]\ttraining's auc: 0.988565\tvalid_1's auc: 0.972995\n",
      "[19200]\ttraining's auc: 0.988821\tvalid_1's auc: 0.973175\n",
      "[19500]\ttraining's auc: 0.989069\tvalid_1's auc: 0.973345\n",
      "[19800]\ttraining's auc: 0.989317\tvalid_1's auc: 0.97351\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's auc: 0.989472\tvalid_1's auc: 0.97361\n",
      "Fold 2 started at Thu Feb 28 22:36:32 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.90158\tvalid_1's auc: 0.894611\n",
      "[600]\ttraining's auc: 0.926176\tvalid_1's auc: 0.919092\n",
      "[900]\ttraining's auc: 0.936965\tvalid_1's auc: 0.929679\n",
      "[1200]\ttraining's auc: 0.943663\tvalid_1's auc: 0.936029\n",
      "[1500]\ttraining's auc: 0.948493\tvalid_1's auc: 0.940656\n",
      "[1800]\ttraining's auc: 0.952359\tvalid_1's auc: 0.944377\n",
      "[2100]\ttraining's auc: 0.955454\tvalid_1's auc: 0.947333\n",
      "[2400]\ttraining's auc: 0.95794\tvalid_1's auc: 0.949669\n",
      "[2700]\ttraining's auc: 0.960028\tvalid_1's auc: 0.951639\n",
      "[3000]\ttraining's auc: 0.961833\tvalid_1's auc: 0.953359\n",
      "[3300]\ttraining's auc: 0.963369\tvalid_1's auc: 0.954782\n",
      "[3600]\ttraining's auc: 0.964671\tvalid_1's auc: 0.955994\n",
      "[3900]\ttraining's auc: 0.9658\tvalid_1's auc: 0.957032\n",
      "[4200]\ttraining's auc: 0.96686\tvalid_1's auc: 0.957971\n",
      "[4500]\ttraining's auc: 0.967799\tvalid_1's auc: 0.958849\n",
      "[4800]\ttraining's auc: 0.968642\tvalid_1's auc: 0.95958\n",
      "[5100]\ttraining's auc: 0.969414\tvalid_1's auc: 0.960279\n",
      "[5400]\ttraining's auc: 0.970141\tvalid_1's auc: 0.960923\n",
      "[5700]\ttraining's auc: 0.9708\tvalid_1's auc: 0.961472\n",
      "[6000]\ttraining's auc: 0.971396\tvalid_1's auc: 0.961966\n",
      "[6300]\ttraining's auc: 0.971977\tvalid_1's auc: 0.962449\n",
      "[6600]\ttraining's auc: 0.972531\tvalid_1's auc: 0.962887\n",
      "[6900]\ttraining's auc: 0.973059\tvalid_1's auc: 0.96329\n",
      "[7200]\ttraining's auc: 0.973579\tvalid_1's auc: 0.963669\n",
      "[7500]\ttraining's auc: 0.974103\tvalid_1's auc: 0.964035\n",
      "[7800]\ttraining's auc: 0.974626\tvalid_1's auc: 0.96439\n",
      "[8100]\ttraining's auc: 0.975132\tvalid_1's auc: 0.964727\n",
      "[8400]\ttraining's auc: 0.975649\tvalid_1's auc: 0.965059\n",
      "[8700]\ttraining's auc: 0.976142\tvalid_1's auc: 0.965375\n",
      "[9000]\ttraining's auc: 0.976631\tvalid_1's auc: 0.965676\n",
      "[9300]\ttraining's auc: 0.977097\tvalid_1's auc: 0.965958\n",
      "[9600]\ttraining's auc: 0.977587\tvalid_1's auc: 0.966257\n",
      "[9900]\ttraining's auc: 0.978072\tvalid_1's auc: 0.966538\n",
      "[10200]\ttraining's auc: 0.978536\tvalid_1's auc: 0.966812\n",
      "[10500]\ttraining's auc: 0.978994\tvalid_1's auc: 0.967085\n",
      "[10800]\ttraining's auc: 0.97944\tvalid_1's auc: 0.967348\n",
      "[11100]\ttraining's auc: 0.979858\tvalid_1's auc: 0.967595\n",
      "[11400]\ttraining's auc: 0.98029\tvalid_1's auc: 0.967859\n",
      "[11700]\ttraining's auc: 0.980712\tvalid_1's auc: 0.968107\n",
      "[12000]\ttraining's auc: 0.981122\tvalid_1's auc: 0.968357\n",
      "[12300]\ttraining's auc: 0.981507\tvalid_1's auc: 0.968567\n",
      "[12600]\ttraining's auc: 0.9819\tvalid_1's auc: 0.968805\n",
      "[12900]\ttraining's auc: 0.982282\tvalid_1's auc: 0.969026\n",
      "[13200]\ttraining's auc: 0.982655\tvalid_1's auc: 0.969251\n",
      "[13500]\ttraining's auc: 0.983022\tvalid_1's auc: 0.969476\n",
      "[13800]\ttraining's auc: 0.983371\tvalid_1's auc: 0.969692\n",
      "[14100]\ttraining's auc: 0.983723\tvalid_1's auc: 0.969899\n",
      "[14400]\ttraining's auc: 0.984063\tvalid_1's auc: 0.970103\n",
      "[14700]\ttraining's auc: 0.984411\tvalid_1's auc: 0.970315\n",
      "[15000]\ttraining's auc: 0.984746\tvalid_1's auc: 0.970514\n",
      "[15300]\ttraining's auc: 0.985072\tvalid_1's auc: 0.9707\n",
      "[15600]\ttraining's auc: 0.9854\tvalid_1's auc: 0.970906\n",
      "[15900]\ttraining's auc: 0.985731\tvalid_1's auc: 0.971102\n",
      "[16200]\ttraining's auc: 0.986034\tvalid_1's auc: 0.971286\n",
      "[16500]\ttraining's auc: 0.986342\tvalid_1's auc: 0.971481\n",
      "[16800]\ttraining's auc: 0.986644\tvalid_1's auc: 0.971669\n",
      "[17100]\ttraining's auc: 0.986939\tvalid_1's auc: 0.971862\n",
      "[17400]\ttraining's auc: 0.987216\tvalid_1's auc: 0.972046\n",
      "[17700]\ttraining's auc: 0.987499\tvalid_1's auc: 0.972219\n",
      "[18000]\ttraining's auc: 0.987779\tvalid_1's auc: 0.972393\n",
      "[18300]\ttraining's auc: 0.988045\tvalid_1's auc: 0.972561\n",
      "[18600]\ttraining's auc: 0.988323\tvalid_1's auc: 0.972736\n",
      "[18900]\ttraining's auc: 0.98858\tvalid_1's auc: 0.972906\n",
      "[19200]\ttraining's auc: 0.988837\tvalid_1's auc: 0.973073\n",
      "[19500]\ttraining's auc: 0.989097\tvalid_1's auc: 0.973244\n",
      "[19800]\ttraining's auc: 0.989351\tvalid_1's auc: 0.973418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's auc: 0.989511\tvalid_1's auc: 0.973536\n",
      "Wall time: 4h 24min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold_n=3\n",
    "\n",
    "folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=30)\n",
    "y_pred_lgb = np.zeros(len(df_test))\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(df_train, target)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = df_train.iloc[train_index], df_train.iloc[valid_index]\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    lgb_model = lgb.train(params, train_data, num_boost_round=20000,\n",
    "                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 200)\n",
    "            \n",
    "    y_pred_lgb += lgb_model.predict(df_test, num_iteration=lgb_model.best_iteration)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgb_smote_2 = pd.DataFrame({\n",
    "        \"ID_code\": test_id,\n",
    "        \"target\": y_pred_lgb\n",
    "    })\n",
    "submission_lgb_smote_2.to_csv('../results/submission_lgb_smote.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
